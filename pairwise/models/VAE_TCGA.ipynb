{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ada1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengqi_xu/.conda/envs/synergyy/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "from itertools import chain\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9cd48ee",
   "metadata": {},
   "source": [
    "#### select ??? genes (top varaince as well as drug-targeted genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc0c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_exp = pd.read_csv(\"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/tcga_exp.csv\")\n",
    "tcga_exp['gene'] = tcga_exp.index\n",
    "selected_genes = pd.read_csv(\"/Users/chengqi_xu/Documents/Elemento lab/synergyy/results/selected_genes.txt\",header=None)\n",
    "selected_genes.columns = ['gene']\n",
    "tcga_exp_merged = pd.merge(selected_genes,tcga_exp,how='left',on='gene')\n",
    "tcga_exp_merged = (tcga_exp_merged.fillna(0).iloc[:,1:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdd340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_exp_merged.columns = selected_genes.gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f64e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_exp = pd.read_csv(\"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/tcga_exp.csv\")\n",
    "\n",
    "ccle_exp = pd.read_csv(\"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/CCLE_exp.csv\",index_col=0)\n",
    "\n",
    "final_table_columns = ccle_exp.index\n",
    "# df = tcga_exp.drop(columns=[col for col in tcga_exp if col not in final_table_columns])\n",
    "df = tcga_exp_merged.drop(columns=[col for col in tcga_exp_merged if col not in final_table_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22050b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12236, 4092)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3925d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = Variable(torch.Tensor(np.array(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270462c6",
   "metadata": {},
   "source": [
    "#### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim: int, latent_dim: int, hidden_dims: list = None, \\\n",
    "        dop: float = 0.1, noise_flag: bool = False, **kwargs) -> None:\n",
    "        super(AE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.noise_flag = noise_flag\n",
    "        self.dop = dop\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512]\n",
    "\n",
    "        # build encoder\n",
    "        modules = []\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dims[0], bias=True),\n",
    "                #nn.BatchNorm1d(hidden_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dop)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i + 1], bias=True),\n",
    "                    #nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(self.dop)\n",
    "                )\n",
    "            )\n",
    "        modules.append(nn.Dropout(self.dop))\n",
    "        modules.append(nn.Linear(hidden_dims[-1], latent_dim, bias=True))\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        # build decoder\n",
    "        modules = []\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dims[-1], bias=True),\n",
    "                #nn.BatchNorm1d(hidden_dims[-1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.dop)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i + 1], bias=True),\n",
    "                    #nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(self.dop)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1], hidden_dims[-1], bias=True),\n",
    "            #nn.BatchNorm1d(hidden_dims[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dop),\n",
    "            nn.Linear(hidden_dims[-1], input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        encoded_input = self.encoder(input)\n",
    "        encoded_input = nn.functional.normalize(encoded_input, p=2, dim=1)\n",
    "        output = self.final_layer(self.decoder(encoded_input))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def encode(self, input):\n",
    "        return self.encoder(input)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7860a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = dataX.shape[1]\n",
    "latent_dim = 256\n",
    "model = AE(input_size,latent_dim)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c8ddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/50], loss:18.4074\n",
      "epoch [2/50], loss:15.8191\n",
      "epoch [3/50], loss:8.3740\n",
      "epoch [4/50], loss:3.4146\n",
      "epoch [5/50], loss:2.4475\n",
      "epoch [6/50], loss:2.1182\n",
      "epoch [7/50], loss:2.0497\n",
      "epoch [8/50], loss:1.9519\n",
      "epoch [9/50], loss:1.9918\n",
      "epoch [10/50], loss:1.9892\n",
      "epoch [11/50], loss:1.9830\n",
      "epoch [12/50], loss:1.9645\n",
      "epoch [13/50], loss:1.9657\n",
      "epoch [14/50], loss:1.9231\n",
      "epoch [15/50], loss:1.9472\n",
      "epoch [16/50], loss:1.8625\n",
      "epoch [17/50], loss:1.8121\n",
      "epoch [18/50], loss:1.8193\n",
      "epoch [19/50], loss:1.7419\n",
      "epoch [20/50], loss:1.6774\n",
      "epoch [21/50], loss:1.7086\n",
      "epoch [22/50], loss:1.6924\n",
      "epoch [23/50], loss:1.6684\n",
      "epoch [24/50], loss:1.6244\n",
      "epoch [25/50], loss:1.6284\n",
      "epoch [26/50], loss:1.5728\n",
      "epoch [27/50], loss:1.5428\n",
      "epoch [28/50], loss:1.5219\n",
      "epoch [29/50], loss:1.5355\n",
      "epoch [30/50], loss:1.4673\n",
      "epoch [31/50], loss:1.4629\n",
      "epoch [32/50], loss:1.4493\n",
      "epoch [33/50], loss:1.5027\n",
      "epoch [34/50], loss:1.4907\n",
      "epoch [35/50], loss:1.4246\n",
      "epoch [36/50], loss:1.4173\n",
      "epoch [37/50], loss:1.3941\n",
      "epoch [38/50], loss:1.3782\n",
      "epoch [39/50], loss:1.3709\n",
      "epoch [40/50], loss:1.3630\n",
      "epoch [41/50], loss:1.3222\n",
      "epoch [42/50], loss:1.3469\n",
      "epoch [43/50], loss:1.3133\n",
      "epoch [44/50], loss:1.2916\n",
      "epoch [45/50], loss:1.3197\n",
      "epoch [46/50], loss:1.2810\n",
      "epoch [47/50], loss:1.2599\n",
      "epoch [48/50], loss:1.2388\n",
      "epoch [49/50], loss:1.2223\n",
      "epoch [50/50], loss:1.2169\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataX, batch_size=512,shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "do = nn.Dropout()  # comment out for standard AE\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img = data\n",
    "        # ===================forward=====================\n",
    "        output = model(img)  # feed  (for std AE) or  (for denoising AE)\n",
    "        loss = criterion(output, img.data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], loss:{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94d618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROOT_DIR = os.path.realpath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "#save_path = os.path.join(ROOT_DIR, 'data','cell_line_data','tcga_encoder.pth')\n",
    "torch.save(model.state_dict(), \"/Users/chengqi_xu/Documents/Elemento lab/synergyy/data/cell_line_data/tcga/tcga_encoder.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('synergyy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c961a5698cf0a06e44a9b39867173e70e7f5b41ad5fe4e792827527847a8f1b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
